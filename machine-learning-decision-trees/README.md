# CO395 Machine Learning - Decision Trees

## Installation

The following Python3.6 packages are required for the program to function properly:

 * **numpy** - For matrix operations
 * **matplotlib.pyplot** - For decision tree visualisation

## Usage

### Configuration

Within the repository contains a `config.ini` file which you will use to adjust the program settings and parameters. 

  * `dataset`: Set this to the path of the file you want to use as your dataset 
  * `pruning_validation_bins`: The number of bins/folds (out of 10) to be used for pruning the decision tree. The remaining bins/folds will be used for the initial training of the decision tree. This is set to 2 by default, and is explained in the assignment report.
  * `display_tree`: Creates and graphically displays the unpruned and pruned trees created from the dataset
  
### Running 

Once configured, run the program by calling in terminal:

```bash
python3 run.py
```
  

## Code Decription

### Base Functions

Within `training.py` lies the following functions:

* `decision_tree_learning(data)`

  This function creates a decision tree in the form of a dictionary object, using the given `data` parameter. The function does not attempt to perform any sort of tuning on the decision tree.

* `evaluate(tree, data)`

  Using the decision tree returned from the `decision_tree_learning` function, this function evaluates and displays on the terminal the performance of the given `tree` on the given `data` dataset.

  The following performance metrics are displayed:
   * Classification rate
   * Precision
   * Recall
   * F1 Measure
   
### Helper Functions

The `run.py` file contains useful helper functions that uses the functions made in `training.py` to automatically perform k-fold cross validation (and other operations) on given datasets. You may find the following functions helpful:

* `cross_validation(data)`

  This function performs a simple 10-fold cross validation on the given dataset, and returns the cumulative confusion matrix generated by 10 iterations of the cross validation.

  The function also displays in the terminal the performance metrics derived from the confusion matrix.

* `cross_validation_with_pruning(data)`

  This function performs also performs a 10-fold cross validation on a given dataset. It uses 1 fold for the testing, and the remaining 9 folds are split into a ratio of 3 (for training) and 6 (for pruning/validation).

  The reasoning for the 3:6 split is detailed in the report and chosen after a round of parameter tuning based on the noisy dataset.

* `find_best_parameter(data)`

  This function determines the best ratio to split a given dataset into training and pruning datasets by cross-validation with parameter tuning.


## Example Outputs

### `cross_validation`

```
-------------------------------------
Classification_Rate: 0.974
Precision: [0.43  0.44  0.12  0.52]
Recall: [0.43  0.44  0.12  0.52]
F1_Measure: [0.43  0.44  0.12  0.52]
-------------------------------------
```
Each column of the `Precision`, `Recall` and `F1_Measure` arrays represent the corresponding values for a given label, in the case of this exercise would be the room number

### `cross_validation_with_pruning`
```
-------------------------------------
Classification_Rate: 0.974
Precision: [0.43  0.44  0.12  0.52]
Recall: [0.43  0.44  0.12  0.52]
F1_Measure: [0.43  0.44  0.12  0.52]
-------------------------------------
```

Each column of the `Precision`, `Recall` and `F1_Measure` arrays represent the corresponding values for a given label, in the case of this exercise would be the room number

### `find_best_parameter`
```
...
%Prune data	 Avg. Depth	 Avg. CR
0.0 		 16.7 		 0.8044
11.1 		 9.1 		 0.8772
22.2 		 9.2 		 0.8838
33.3 		 9.9 		 0.8853
44.4 		 8.0 		 0.8831
55.6 		 7.4 		 0.8856
66.7 		 7.6 		 0.8858
77.8 		 6.4 		 0.8777
88.9 		 5.0 		 0.8646

Best ratio of data to use for validation (pruning) is: [ 66.7]%
```

## License
[MIT](https://choosealicense.com/licenses/mit/)
